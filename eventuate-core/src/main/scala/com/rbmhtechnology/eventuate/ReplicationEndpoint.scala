/*
 * Copyright 2015 - 2016 Red Bull Media House GmbH <http://www.redbullmediahouse.com> - all rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.rbmhtechnology.eventuate

import java.util.concurrent.TimeUnit
import java.util.concurrent.atomic.AtomicBoolean
import java.util.function.{ Function => JFunction }

import akka.actor._
import akka.pattern.ask
import akka.pattern.pipe
import akka.util.Timeout

import com.rbmhtechnology.eventuate.EventsourcingProtocol.Delete
import com.rbmhtechnology.eventuate.EventsourcingProtocol.DeleteFailure
import com.rbmhtechnology.eventuate.EventsourcingProtocol.DeleteSuccess
import com.rbmhtechnology.eventuate.ReplicationFilter.NoFilter
import com.rbmhtechnology.eventuate.ReplicationProtocol.ReplicationEndpointInfo

import com.typesafe.config.Config

import scala.collection.JavaConverters._
import scala.collection.immutable.Seq
import scala.concurrent._
import scala.concurrent.duration._

import ReplicationProtocol._

class ReplicationSettings(config: Config) {
  val writeBatchSize: Int =
    config.getInt("eventuate.log.write-batch-size")

  val writeTimeout: FiniteDuration =
    config.getDuration("eventuate.log.write-timeout", TimeUnit.MILLISECONDS).millis

  val readTimeout: FiniteDuration =
    config.getDuration("eventuate.log.read-timeout", TimeUnit.MILLISECONDS).millis

  val remoteReadTimeout: FiniteDuration =
    config.getDuration("eventuate.log.replication.remote-read-timeout", TimeUnit.MILLISECONDS).millis

  val remoteScanLimit: Int =
    config.getInt("eventuate.log.replication.remote-scan-limit")

  val retryDelay: FiniteDuration =
    config.getDuration("eventuate.log.replication.retry-delay", TimeUnit.MILLISECONDS).millis

  val failureDetectionLimit: FiniteDuration =
    config.getDuration("eventuate.log.replication.failure-detection-limit", TimeUnit.MILLISECONDS).millis

  require(failureDetectionLimit >= remoteReadTimeout + retryDelay, s"""
     |eventuate.log.replication.failure-detection-limit ($failureDetectionLimit) must be at least the sum of
     |eventuate.log.replication.retry-delay ($retryDelay) and
     |eventuate.log.replication.remote-read-timeout ($remoteReadTimeout)
   """.stripMargin)
}

object ReplicationEndpoint {
  /**
   * Default log name.
   */
  val DefaultLogName: String = "default"

  /**
   * Default application name.
   */
  val DefaultApplicationName: String = "default"

  /**
   * Default application version.
   */
  val DefaultApplicationVersion: ApplicationVersion = ApplicationVersion()

  /**
   * Published to the actor system's event stream if a remote log is available.
   */
  case class Available(endpointId: String, logName: String)

  /**
   * Published to the actor system's event stream if a remote log is unavailable.
   */
  case class Unavailable(endpointId: String, logName: String, causes: Seq[Throwable])

  /**
   * Matches a string of format "<hostname>:<port>".
   */
  private object Address {
    def unapply(s: String): Option[(String, Int)] = {
      val hp = s.split(":")
      Some((hp(0), hp(1).toInt))
    }
  }

  /**
   * Creates a [[ReplicationEndpoint]] with a single event log with name [[DefaultLogName]]. The
   * replication endpoint id and replication connections must be configured as follows in `application.conf`:
   *
   * {{{
   *   eventuate.endpoint.id = "endpoint-id"
   *   eventuate.endpoint.connections = ["host-1:port-1", "host-2:port-2", ..., "host-n:port-n"]
   * }}}
   *
   * Optionally, the `applicationName` and `applicationVersion` of a replication endpoint can be
   * configured with e.g.
   *
   * {{{
   *   eventuate.endpoint.application.name = "my-app"
   *   eventuate.endpoint.application.version = "1.2"
   * }}}
   *
   * @param logFactory Factory of log actor `Props`. The `String` parameter of the factory is a unique
   *                   log id generated by this endpoint. The log actor must be assigned this log id.
   */
  def apply(logFactory: String => Props)(implicit system: ActorSystem): ReplicationEndpoint = {
    val config = system.settings.config
    val connections = config.getStringList("eventuate.endpoint.connections").asScala.toSet[String].map {
      case Address(host, port) => ReplicationConnection(host, port)
    }
    apply(logFactory, connections)
  }

  /**
   * Creates a [[ReplicationEndpoint]] with a single event log with name [[DefaultLogName]]. The
   * replication endpoint id must be configured as follows in `application.conf`:
   *
   * {{{
   *   eventuate.endpoint.id = "endpoint-id"
   * }}}
   *
   * Optionally, the `applicationName` and `applicationVersion` of a replication endpoint can be
   * configured with e.g.
   *
   * {{{
   *   eventuate.endpoint.application.name = "my-app"
   *   eventuate.endpoint.application.version = "1.2"
   * }}}
   *
   * @param logFactory Factory of log actor `Props`. The `String` parameter of the factory is a unique
   *                   log id generated by this endpoint. The log actor must be assigned this log id.
   * @param connections Replication connections to other replication endpoints.
   */
  def apply(logFactory: String => Props, connections: Set[ReplicationConnection])(implicit system: ActorSystem): ReplicationEndpoint = {
    val config = system.settings.config
    val endpointId = config.getString("eventuate.endpoint.id")

    val applicationName =
      if (config.hasPath("eventuate.endpoint.application.name")) config.getString("eventuate.endpoint.application.name")
      else DefaultApplicationName

    val applicationVersion =
      if (config.hasPath("eventuate.endpoint.application.version")) ApplicationVersion(config.getString("eventuate.endpoint.application.version"))
      else DefaultApplicationVersion

    new ReplicationEndpoint(endpointId, Set(ReplicationEndpoint.DefaultLogName), logFactory, connections, Map.empty, applicationName, applicationVersion)(system)
  }

  /**
   * Java API that creates a [[ReplicationEndpoint]].
   *
   * Creates a [[ReplicationEndpoint]] with a single event log with name [[DefaultLogName]]. The
   * replication endpoint id and replication connections must be configured as follows in `application.conf`:
   *
   * {{{
   *   eventuate.endpoint.id = "endpoint-id"
   *   eventuate.endpoint.connections = ["host-1:port-1", "host-2:port-2", ..., "host-n:port-n"]
   * }}}
   *
   * Optionally, the `applicationName` and `applicationVersion` of a replication endpoint can be
   * configured with e.g.
   *
   * {{{
   *   eventuate.endpoint.application.name = "my-app"
   *   eventuate.endpoint.application.version = "1.2"
   * }}}
   *
   * @param logFactory Factory of log actor `Props`. The `String` parameter of the factory is a unique
   *                   log id generated by this endpoint. The log actor must be assigned this log id.
   */
  def create(logFactory: JFunction[String, Props], system: ActorSystem) =
    apply(id => logFactory.apply(id))(system)
}

/**
 * A replication endpoint connects to other replication endpoints for replicating events. Events are
 * replicated from the connected endpoints to this endpoint. The connected endpoints are ''replication
 * sources'', this endpoint is a ''replication target''. To setup bi-directional replication, the other
 * replication endpoints must additionally setup replication connections to this endpoint.
 *
 * A replication endpoint manages one or more event logs. Event logs are indexed by name. Events are
 * replicated only between event logs with matching names.
 *
 * If `applicationName` equals that of a replication source, events are only replicated if `applicationVersion`
 * is greater than or equal to that of the replication source. This is a simple mechanism to support
 * incremental version upgrades of replicated applications where each replica can be upgraded individually
 * without shutting down other replicas. This avoids permanent state divergence during upgrade which may
 * occur if events are replicated from replicas with higher version to those with lower version. If
 * `applicationName` does not equal that of a replication source, events are always replicated, regardless
 * of the `applicationVersion` value.
 *
 * @param id Unique replication endpoint id.
 * @param logNames Names of the event logs managed by this replication endpoint.
 * @param logFactory Factory of log actor `Props`. The `String` parameter of the factory is a unique
 *                   log id generated by this endpoint. The log actor must be assigned this log id.
 * @param connections Replication connections to other replication endpoints.
 * @param filters Replication filters applied locally. Filters are applied when replicating to
 *               individual target logs (keys are log ids of remote logs) or from individual
 *               local logs to all corresponding targets logs (keys are log-names).
 * @param applicationName Name of the application that creates this replication endpoint.
 * @param applicationVersion Version of the application that creates this replication endpoint.
 */
class ReplicationEndpoint(
  val id: String,
  val logNames: Set[String],
  val logFactory: String => Props,
  val connections: Set[ReplicationConnection],
  val filters: Map[String, ReplicationFilter] = Map.empty,
  val applicationName: String = ReplicationEndpoint.DefaultApplicationName,
  val applicationVersion: ApplicationVersion = ReplicationEndpoint.DefaultApplicationVersion)(implicit val system: ActorSystem) {

  import Acceptor._

  private val active: AtomicBoolean =
    new AtomicBoolean(false)

  /**
   * The actor system's replication settings.
   */
  val settings =
    new ReplicationSettings(system.settings.config)

  /**
   * The log actors managed by this endpoint, indexed by their name.
   */
  val logs: Map[String, ActorRef] =
    logNames.map(logName => logName -> system.actorOf(logFactory(logId(logName)), logId(logName))).toMap

  private[eventuate] val connectors: Set[SourceConnector] =
    connections.map(new SourceConnector(this, _))

  private[eventuate] lazy val acceptor: ActorRef =
    system.actorOf(Props(new Acceptor(this)), name = Acceptor.Name)

  /**
   * Returns the unique log id for given `logName`.
   */
  def logId(logName: String): String =
    ReplicationEndpointInfo.logId(id, logName)

  /**
   * Runs an asynchronous disaster recovery procedure. This procedure recovers this endpoint in case of total or
   * partial event loss. Partial event loss means event loss from a given sequence number upwards (for example,
   * after having installed a storage backup). Recovery copies events from directly connected remote endpoints back
   * to this endpoint and automatically removes invalid snapshots. A snapshot is invalid if it covers events that
   * have been lost.
   *
   * This procedure requires that event replication between this and directly connected endpoints is bi-directional
   * and that these endpoints are available during recovery. After successful recovery the endpoint is automatically
   * activated. A failed recovery completes with a [[RecoveryException]] and must be retried. Activating this endpoint
   * without having successfully recovered from partial or total event loss may result in inconsistent replica states.
   *
   * Running a recovery on an endpoint that didn't loose events has no effect but may still fail due to unavailable
   * replication partners, for example. In this case, a recovery retry can be omitted if the `partialUpdate` field
   * of [[RecoveryException]] is set to `false`.
   */
  def recover(): Future[Unit] = {
    if (connections.isEmpty)
      Future.failed(new IllegalStateException("Recover an endpoint without connections"))
    else if (active.compareAndSet(false, true)) {
      import system.dispatcher

      val promise = Promise[Unit]()
      val recovery = new Recovery(this)

      def recoveryFailure[U](partialUpdate: Boolean): PartialFunction[Throwable, Future[U]] = {
        case t => Future.failed(new RecoveryException(t, partialUpdate))
      }

      val recoveryOperation = for {
        infos <- recovery.readEndpointInfos.recoverWith(recoveryFailure(partialUpdate = false))
        clocks <- recovery.readEventLogClocks.recoverWith(recoveryFailure(partialUpdate = false))
        links = recovery.recoveryLinks(infos, clocks)
        _ <- recovery.deleteSnapshots(links).recoverWith(recoveryFailure(partialUpdate = true))
      } yield acceptor ! Recover(links, promise)

      recoveryOperation.onFailure {
        case ex => promise.failure(ex)
      }

      promise.future
    } else Future.failed(new IllegalStateException("Recovery running or endpoint already activated"))
  }

  /**
   * Delete events from a local log identified by `logName` with a sequence number less than or equal to
   * `toSequenceNr`. Deletion is split into logical deletion and physical deletion. Logical deletion is
   * supported by any storage backend and ensures that deleted events are not replayed any more. It has
   * immediate effect. Logically deleted events can still be replicated to remote [[ReplicationEndpoint]]s.
   * They are only physically deleted if the storage backend supports that (currently LevelDB only). Furthermore,
   * physical deletion only starts after all remote replication endpoints identified by `remoteEndpointIds`
   * have successfully replicated these events. Physical deletion is implemented as reliable background
   * process that survives event log restarts.
   *
   * Use with care! When events are physically deleted they cannot be replicated any more to new replication
   * endpoints (i.e. those that were unknown at the time of deletion). Also, a location with deleted events
   * may not be suitable any more for disaster recovery of other locations.
   *
   * @param logName Events are deleted from the local log with this name.
   * @param toSequenceNr Sequence number up to which events shall be deleted (inclusive).
   * @param remoteEndpointIds A set of remote [[ReplicationEndpoint]] ids that must have replicated events
   *                          to their logs before they are allowed to be physically deleted at this endpoint.
   * @return The sequence number up to which events have been logically deleted. When the returned `Future`
   *         completes logical deletion is effective. The returned sequence number can differ from the requested
   *         one, if:
   *
   *         - the log's current sequence number is smaller than the requested number. In this case the current
   *          sequence number is returned.
   *         - there was a previous successful deletion request with a higher sequence number. In this case that
   *          number is returned.
   */
  def delete(logName: String, toSequenceNr: Long, remoteEndpointIds: Set[String]): Future[Long] = {
    import system.dispatcher
    implicit val timeout = Timeout(settings.writeTimeout)
    (logs(logName) ? Delete(toSequenceNr, remoteEndpointIds.map(ReplicationEndpointInfo.logId(_, logName)))).flatMap {
      case DeleteSuccess(deletedTo) => Future.successful(deletedTo)
      case DeleteFailure(ex)        => Future.failed(ex)
    }
  }

  /**
   * Activates this endpoint by starting event replication from remote endpoints to this endpoint.
   */
  def activate(): Unit = if (active.compareAndSet(false, true)) {
    acceptor ! Process
    connectors.foreach(_.activate())
  } else throw new IllegalStateException("Recovery running or endpoint already activated")

  /**
   * Creates [[ReplicationTarget]] for given `logName`.
   */
  private[eventuate] def target(logName: String): ReplicationTarget =
    ReplicationTarget(this, logName, logId(logName), logs(logName))

  /**
   * Returns all log names this endpoint and `endpointInfo` have in common.
   */
  private[eventuate] def commonLogNames(endpointInfo: ReplicationEndpointInfo) =
    this.logNames.intersect(endpointInfo.logNames)
}

/**
 * References a remote event log at a source [[ReplicationEndpoint]].
 */
private case class ReplicationSource(
  endpointId: String,
  logName: String,
  logId: String,
  acceptor: ActorSelection)

/**
 * References a local event log at a target [[ReplicationEndpoint]].
 */
private case class ReplicationTarget(
  endpoint: ReplicationEndpoint,
  logName: String,
  logId: String,
  log: ActorRef) {
}

/**
 * Represents an unidirectional replication link between a `source` and a `target`.
 */
private case class ReplicationLink(
  source: ReplicationSource,
  target: ReplicationTarget)

private class SourceConnector(val targetEndpoint: ReplicationEndpoint, val connection: ReplicationConnection) {
  def links(sourceInfo: ReplicationEndpointInfo): Set[ReplicationLink] =
    targetEndpoint.commonLogNames(sourceInfo).map { logName =>
      val sourceLogId = sourceInfo.logId(logName)
      val source = ReplicationSource(sourceInfo.endpointId, logName, sourceLogId, remoteAcceptor)
      ReplicationLink(source, targetEndpoint.target(logName))
    }

  def activate(): Unit =
    targetEndpoint.system.actorOf(Props(new Connector(this)))

  def remoteAcceptor: ActorSelection =
    remoteActorSelection(Acceptor.Name)

  def remoteActorSelection(actor: String): ActorSelection = {
    import connection._

    val protocol = targetEndpoint.system match {
      case sys: ExtendedActorSystem => sys.provider.getDefaultAddress.protocol
      case sys                      => "akka.tcp"
    }

    targetEndpoint.system.actorSelection(s"${protocol}://${name}@${host}:${port}/user/${actor}")
  }
}

/**
 * Reliably sends [[GetReplicationEndpointInfo]] requests to the [[Acceptor]] at a source [[ReplicationEndpoint]].
 * On receiving a [[GetReplicationEndpointInfoSuccess]] reply, this connector sets up log [[Replicator]]s, one per
 * common log name between source and target endpoints.
 */
private class Connector(sourceConnector: SourceConnector) extends Actor {
  import context.dispatcher

  private val acceptor = sourceConnector.remoteAcceptor
  private var acceptorRequestSchedule: Option[Cancellable] = None

  private var connected = false

  def receive = {
    case GetReplicationEndpointInfoSuccess(info) if !connected =>
      sourceConnector.links(info).foreach {
        case ReplicationLink(source, target) =>
          val filter = sourceConnector.connection.filters.get(target.logName) match {
            case Some(f) => f
            case None    => NoFilter
          }
          context.actorOf(Props(new Replicator(target, source, filter)))

      }
      connected = true
      acceptorRequestSchedule.foreach(_.cancel())
  }

  private def scheduleAcceptorRequest(acceptor: ActorSelection): Cancellable =
    context.system.scheduler.schedule(0.seconds, sourceConnector.targetEndpoint.settings.retryDelay, new Runnable {
      override def run() = acceptor ! GetReplicationEndpointInfo
    })

  override def preStart(): Unit =
    acceptorRequestSchedule = Some(scheduleAcceptorRequest(acceptor))

  override def postStop(): Unit =
    acceptorRequestSchedule.foreach(_.cancel())
}

/**
 * Replicates events from a remote source log to a local target log. This replicator guarantees that
 * the ordering of replicated events is preserved. Potential duplicates are either detected at source
 * (which is an optimization) or at target (for correctness). Duplicate detection is based on tracked
 * event vector times.
 */
private class Replicator(target: ReplicationTarget, source: ReplicationSource, filter: ReplicationFilter) extends Actor with ActorLogging {
  import FailureDetector._
  import target.endpoint.settings
  import context.dispatcher

  val scheduler = context.system.scheduler
  val detector = context.actorOf(Props(new FailureDetector(source.endpointId, source.logName, settings.failureDetectionLimit)))

  var readSchedule: Option[Cancellable] = None

  val fetching: Receive = {
    case GetReplicationProgressSuccess(_, storedReplicationProgress, currentTargetVersionVector) =>
      context.become(reading)
      read(storedReplicationProgress, currentTargetVersionVector)
    case GetReplicationProgressFailure(cause) =>
      log.error(cause, "replication progress read failed")
      scheduleFetch()
  }

  val idle: Receive = {
    case ReplicationDue =>
      readSchedule.foreach(_.cancel()) // if it's notification from source concurrent to a scheduled read
      context.become(fetching)
      fetch()
  }

  val reading: Receive = {
    case ReplicationReadSuccess(events, fromSequenceNr, replicationProgress, _, currentSourceVersionVector) =>
      detector ! AvailabilityDetected
      context.become(writing)
      write(events, replicationProgress, currentSourceVersionVector, replicationProgress >= fromSequenceNr)
    case ReplicationReadFailure(cause, _) =>
      detector ! FailureDetected(cause)
      log.error(cause, s"replication read failed")
      context.become(idle)
      scheduleRead()
  }

  val writing: Receive = {
    case writeSuccess @ ReplicationWriteSuccess(_, storedReplicationProgress, _, _, false) =>
      notifyLocalAcceptor(writeSuccess)
      context.become(idle)
      scheduleRead()
    case writeSuccess @ ReplicationWriteSuccess(_, storedReplicationProgress, _, currentTargetVersionVector, true) =>
      notifyLocalAcceptor(writeSuccess)
      context.become(reading)
      read(storedReplicationProgress, currentTargetVersionVector)
    case ReplicationWriteFailure(cause) =>
      log.error(cause, "replication write failed")
      context.become(idle)
      scheduleRead()
  }

  def receive = fetching

  override def unhandled(message: Any): Unit = message match {
    case ReplicationDue => // currently replicating, ignore
    case other          => super.unhandled(message)
  }

  private def notifyLocalAcceptor(writeSuccess: ReplicationWriteSuccess): Unit =
    target.endpoint.acceptor ! writeSuccess

  private def scheduleFetch(): Unit =
    scheduler.scheduleOnce(settings.retryDelay)(fetch())

  private def scheduleRead(): Unit =
    readSchedule = Some(scheduler.scheduleOnce(settings.retryDelay, self, ReplicationDue))

  private def fetch(): Unit = {
    implicit val timeout = Timeout(settings.readTimeout)

    target.log ? GetReplicationProgress(source.logId) recover {
      case t => GetReplicationProgressFailure(t)
    } pipeTo self
  }

  private def read(storedReplicationProgress: Long, currentTargetVersionVector: VectorTime): Unit = {
    implicit val timeout = Timeout(settings.remoteReadTimeout)
    val replicationRead = ReplicationRead(storedReplicationProgress + 1, settings.writeBatchSize, settings.remoteScanLimit, filter, target.logId, self, currentTargetVersionVector)

    (source.acceptor ? ReplicationReadEnvelope(replicationRead, source.logName, target.endpoint.applicationName, target.endpoint.applicationVersion)) recover {
      case t => ReplicationReadFailure(ReplicationReadTimeoutException(settings.remoteReadTimeout), target.logId)
    } pipeTo self
  }

  private def write(events: Seq[DurableEvent], replicationProgress: Long, currentSourceVersionVector: VectorTime, continueReplication: Boolean): Unit = {
    implicit val timeout = Timeout(settings.writeTimeout)

    target.log ? ReplicationWrite(events, replicationProgress, source.logId, currentSourceVersionVector, continueReplication) recover {
      case t => ReplicationWriteFailure(t)
    } pipeTo self
  }

  override def preStart(): Unit =
    fetch()

  override def postStop(): Unit =
    readSchedule.foreach(_.cancel())
}

private object FailureDetector {
  case object AvailabilityDetected
  case class FailureDetected(cause: Throwable)
  case class FailureDetectionLimitReached(counter: Int)
}

private class FailureDetector(sourceEndpointId: String, logName: String, failureDetectionLimit: FiniteDuration) extends Actor {
  import ReplicationEndpoint._
  import FailureDetector._
  import context.dispatcher

  private var counter: Int = 0
  private var causes: Vector[Throwable] = Vector.empty
  private var schedule: Cancellable = scheduleFailureDetectionLimitReached()

  private val failureDetectionLimitNanos = failureDetectionLimit.toNanos
  private var lastReportedAvailability: Long = 0L

  def receive = {
    case AvailabilityDetected =>
      val currentTime = System.nanoTime()
      val lastInterval = currentTime - lastReportedAvailability
      if (lastInterval >= failureDetectionLimitNanos) {
        context.system.eventStream.publish(Available(sourceEndpointId, logName))
        lastReportedAvailability = currentTime
      }
      schedule.cancel()
      schedule = scheduleFailureDetectionLimitReached()
      causes = Vector.empty
    case FailureDetected(cause) =>
      causes = causes :+ cause
    case FailureDetectionLimitReached(scheduledCount) if scheduledCount == counter =>
      context.system.eventStream.publish(Unavailable(sourceEndpointId, logName, causes))
      schedule = scheduleFailureDetectionLimitReached()
      causes = Vector.empty
  }

  private def scheduleFailureDetectionLimitReached(): Cancellable = {
    counter += 1
    context.system.scheduler.scheduleOnce(failureDetectionLimit, self, FailureDetectionLimitReached(counter))
  }
}
