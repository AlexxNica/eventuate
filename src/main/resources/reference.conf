akka {
  actor {
    serializers {
      eventuate-durable-event = "com.rbmhtechnology.eventuate.serializer.DurableEventSerializer"
      eventuate-replication-filter = "com.rbmhtechnology.eventuate.serializer.ReplicationFilterSerializer"
      eventuate-replication-protocol = "com.rbmhtechnology.eventuate.serializer.ReplicationProtocolSerializer"
    }

    serialization-bindings {
      "com.rbmhtechnology.eventuate.DurableEvent" = eventuate-durable-event
      "com.rbmhtechnology.eventuate.DurableEventBatch" = eventuate-durable-event
      "com.rbmhtechnology.eventuate.ReplicationFilter$Format" = eventuate-replication-filter
      "com.rbmhtechnology.eventuate.ReplicationProtocol$Format" = eventuate-replication-protocol
    }
  }
}

eventuate {
  log.write {
    # Maximum write batch size for emitted events by event-sourced actors. It
    # is exceeded if the number of events in a single write request is higher
    # than batch-size-max.
    batch-size-max = 200
  }

  log.replication {
    # Maximum batch size for event replication and event writing to the target
    # event log.
    batch-size-max = 200

    # Event replication retry interval. Event replication is re-tried at this
    # interval if previous transfer batch was empty or failed.
    retry-interval = 5s

    # Timeout for reading events from the remote source log.
    read-timeout = 10s

    # Timeout for writing events to the local target log.
    write-timeout = 10s

    # Maximum duration of missing heartbeats from a remote location until
    # that location is considered unavailable.
    failure-detection-limit = 60s
  }

  log.leveldb {
    # Root directory for storing the log directories of individual event logs.
    dir = target

    # Use fsync on write.
    fsync = on

    write-dispatcher {
      executor = "thread-pool-executor"
      type = PinnedDispatcher
    }

    read-dispatcher {
      type = Dispatcher
      executor = "fork-join-executor"
      fork-join-executor {
        parallelism-min = 2
        parallelism-max = 8
      }
    }
  }

  log.cassandra {
    # Comma-separated list of contact points in the cluster (comma-separated
    # hostname or hostname:port list).
    contact-points = ["127.0.0.1"]

    # Default port of contact points in the cluster. Ports defined in
    # contact-points override this setting.
    default-port = 9042

    # Name of the keyspace created/used by Eventuate.
    keyspace = "eventuate"

    # Whether or not to auto-create the keyspace.
    keyspace-autocreate = true

    # Prefix of all tables created/used by Eventuate.
    table-prefix = "log"

    # Replication factor to use when creating the keyspace.
    replication-factor = 1

    # Write consistency level
    write-consistency = "QUORUM"

    # Read consistency level
    read-consistency = "QUORUM"

    # Maximum number of rows in a result set.
    max-result-set-size = 1000

    # Retry backoff for event log initialization. Initialization requires
    # reading the last indexed sequence number and indexing of not yet
    # indexed log entries.
    init-retry-backoff = 5s

    # Number of new events that must have been written before another index
    # update is triggered.
    index-update-limit = 100

    write-dispatcher {
      executor = "thread-pool-executor"
      type = PinnedDispatcher
    }

    read-dispatcher {
      type = Dispatcher
      executor = "fork-join-executor"
      fork-join-executor {
        parallelism-min = 2
        parallelism-max = 16
      }
    }
  }
}
