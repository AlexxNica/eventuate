/*
 * Copyright (C) 2015 Red Bull Media House GmbH <http://www.redbullmediahouse.com> - all rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.rbmhtechnology.eventuate

import java.util.concurrent.TimeUnit
import java.util.function.{Function => JFunction}

import akka.actor._
import akka.pattern.ask
import akka.pattern.pipe
import akka.util.Timeout

import com.typesafe.config.Config

import scala.collection.JavaConverters._
import scala.collection.immutable.Seq
import scala.concurrent.duration._

import ReplicationProtocol._

private[eventuate] class ReplicationSettings(config: Config) {
  val retryInterval: FiniteDuration =
    config.getDuration("eventuate.log.replication.retry-interval", TimeUnit.MILLISECONDS).millis

  val readTimeout: FiniteDuration =
    config.getDuration("eventuate.log.replication.read-timeout", TimeUnit.MILLISECONDS).millis

  val writeTimeout: FiniteDuration =
    config.getDuration("eventuate.log.replication.write-timeout", TimeUnit.MILLISECONDS).millis

  val batchSizeMax: Int =
    config.getInt("eventuate.log.replication.batch-size-max")

  val failureDetectionLimit =
    config.getDuration("eventuate.log.replication.failure-detection-limit", TimeUnit.MILLISECONDS).millis
}

object ReplicationEndpoint {
  /**
   * Default log name.
   */
  val DefaultLogName: String = "default"

  /**
   * Published to the actor system's event stream if a remote log is available.
   */
  case class Available(endpointId: String, logName: String)

  /**
   * Published to the actor system's event stream if a remote log is unavailable.
   */
  case class Unavailable(endpointId: String, logName: String)

  /**
   * Matches a string of format "<hostname>:<port>".
   */
  private object Address {
    def unapply(s: String): Option[(String, Int)] = {
      val hp = s.split(":")
      Some((hp(0), hp(1).toInt))
    }
  }

  /**
   * Creates a [[ReplicationEndpoint]] with a single event log with name [[DefaultLogName]]. The
   * replication endpoint id and replication connections must be configured as follows in `application.conf`:
   *
   * {{{
   *   endpoint.id = "endpoint-id"
   *   endpoint.connections = ["host-1:port-1", "host-2:port-2", ..., "host-n:port-n"]
   * }}}
   *
   * @param logFactory Factory of log actor `Props`. The `String` parameter of the factory is a unique
   *                   log id generated by this endpoint. The log actor must be assigned this log id.
   */
  def apply(logFactory: String => Props)(implicit system: ActorSystem): ReplicationEndpoint = {
    val config = system.settings.config
    val connections = config.getStringList("eventuate.endpoint.connections").asScala.toSet[String].map {
      case Address(host, port) => ReplicationConnection(host, port)
    }
    apply(logFactory, connections)
  }

  /**
   * Creates a [[ReplicationEndpoint]] with a single event log with name [[DefaultLogName]]. The
   * replication endpoint id must be configured as follows in `application.conf`:
   *
   * {{{
   *   endpoint.id = "endpoint-id"
   * }}}
   *
   * @param logFactory Factory of log actor `Props`. The `String` parameter of the factory is a unique
   *                   log id generated by this endpoint. The log actor must be assigned this log id.
   * @param connections Replication connections to other replication endpoints.
   */
  def apply(logFactory: String => Props, connections: Set[ReplicationConnection])(implicit system: ActorSystem): ReplicationEndpoint = {
    val config = system.settings.config
    val endpointId = config.getString("eventuate.endpoint.id")
    new ReplicationEndpoint(endpointId, Set(ReplicationEndpoint.DefaultLogName), logFactory, connections)(system)
  }

  /**
   * Java API.
   *
   * Creates a [[ReplicationEndpoint]] with a single event log with name [[DefaultLogName]]. The
   * replication endpoint id and replication connections must be configured as follows in `application.conf`:
   *
   * {{{
   *   endpoint.id = "endpoint-id"
   *   endpoint.connections = ["host-1:port-1", "host-2:port-2", ..., "host-n:port-n"]
   * }}}
   *
   * @param logFactory Factory of log actor `Props`. The `String` parameter of the factory is a unique
   *                   log id generated by this endpoint. The log actor must be assigned this log id.
   */
  def create(logFactory: JFunction[String, Props], system: ActorSystem) =
    apply(id => logFactory.apply(id))(system)
}

/**
 * A replication endpoint connects to other replication endpoints for replicating events. Events are
 * replicated from the connected endpoints to this endpoint. The connected endpoints are ''replication
 * sources'', this endpoint is a ''replication target''. To setup bi-directional replication, the other
 * replication endpoints must additionally setup replication connections to this endpoint.
 *
 * A replication endpoint manages one or more event logs. Event logs are indexed by name. Events are
 * replicated only between event logs with matching names.
 *
 * @param id Unique replication endpoint id.
 * @param logNames Names of the event logs managed by this replication endpoint.
 * @param logFactory Factory of log actor `Props`. The `String` parameter of the factory is a unique
 *                   log id generated by this endpoint. The log actor must be assigned this log id.
 * @param connections Replication connections to other replication endpoints.
 */
class ReplicationEndpoint(val id: String, val logNames: Set[String], logFactory: String => Props, connections: Set[ReplicationConnection])(implicit system: ActorSystem) { endpoint =>
  /**
   * This replication endpoint's info object.
   */
  private val info: ReplicationEndpointInfo =
    ReplicationEndpointInfo(id, logNames)

  /**
   * The actor system's replication settings.
   */
  private[eventuate] val settings =
    new ReplicationSettings(system.settings.config)

  /**
   * The log actors managed by this endpoint, indexed by their name.
   */
  val logs: Map[String, ActorRef] =
    logNames.map(logName => logName -> system.actorOf(logFactory(logId(logName)), name = logId(logName))).toMap

  /**
   * Returns the unique log id for given `logName`.
   */
  def logId(logName: String): String =
    info.logId(logName)

  system.actorOf(Props(new SourceReplicationConnector(info)), name = SourceReplicationConnector.Name)
  system.actorOf(Props(new NotificationChannel), name = NotificationChannel.Name)

  connections.map { connection =>
    system.actorOf(Props(new TargetReplicationConnector(endpoint, connection)))
  }
}

/**
 * References a remote replication source.
 */
private case class ReplicationSource(
  endpointId: String,
  logName: String,
  logId: String,
  log: ActorSelection)

/**
 * References a local replication target.
 */
private case class ReplicationTarget(
  endpoint: ReplicationEndpoint,
  logName: String,
  logId: String,
  log: ActorRef)

private object SourceReplicationConnector {
  val Name = "connector"
}

/**
 * Replication connector at a source [[ReplicationEndpoint]].
 */
private class SourceReplicationConnector(sourceEndpointInfo: ReplicationEndpointInfo) extends Actor {
  def receive = {
    case GetReplicationEndpointInfo =>
      sender() ! GetReplicationEndpointInfoSuccess(sourceEndpointInfo)
  }
}

/**
 * Replication connector at a target [[ReplicationEndpoint]]. Obtains a [[ReplicationEndpointInfo]]
 * object from a source replication endpoint for settings up log [[Replicator]]s, one per common log
 * name.
 */
private class TargetReplicationConnector(targetEndpoint: ReplicationEndpoint, connection: ReplicationConnection) extends Actor {
  import context.dispatcher

  private val connector = selection(SourceReplicationConnector.Name)
  private val schedule = context.system.scheduler.schedule(0.seconds, targetEndpoint.settings.retryInterval, new Runnable {
    override def run() = connector ! GetReplicationEndpointInfo
  })

  private var connected = false

  def receive = {
    case GetReplicationEndpointInfoSuccess(info) if !connected =>
      info.logNames.intersect(targetEndpoint.logNames).foreach { logName =>
        val sourceLogId = info.logId(logName)
        val source = ReplicationSource(info.endpointId, logName, sourceLogId, selection(sourceLogId))
        val target = ReplicationTarget(targetEndpoint, logName, targetEndpoint.logId(logName), targetEndpoint.logs(logName))
        context.actorOf(Props(new Replicator(source, target, connection.filters.get(logName), selection(NotificationChannel.Name))))
      }
      connected = true
      schedule.cancel()
  }

  private def selection(actor: String): ActorSelection = {
    import connection._

    val protocol = context.system match {
      case sys: ExtendedActorSystem => sys.provider.getDefaultAddress.protocol
      case sys                      => "akka.tcp"
    }

    context.actorSelection(s"${protocol}://${name}@${host}:${port}/user/${actor}")
  }

  override def postStop(): Unit =
    schedule.cancel()
}

/**
 * Replicates events from a remote source log to a local target log. This replicator guarantees that
 *
 *  - the ordering of replicated events is preserved
 *  - no duplicates are written to the target log
 *
 *  The second guarantee requires the target log to store the replication progress (`lastSourceLogSequenceNrStored`)
 *  with read-your-write consistency to the target log. Whenever writing to the target log fails, the replication
 *  progress is recovered by this replicator and replication is resumed from that state.
 */
private class Replicator(source: ReplicationSource, target: ReplicationTarget, filter: Option[ReplicationFilter], notificationChannel: ActorSelection) extends Actor with ActorLogging {
  import ReplicationServerFailureDetector._
  import target.endpoint.settings
  import context.dispatcher

  val scheduler = context.system.scheduler
  val replicationFilter = filter match {
    case Some(f) => SourceLogIdExclusionFilter(target.logId).and(f)
    case None    => SourceLogIdExclusionFilter(target.logId)
  }

  val failureDetector = context.actorOf(Props(new ReplicationServerFailureDetector(source.endpointId, source.logName, settings.failureDetectionLimit)))
  val registrationSchedule = context.system.scheduler.schedule(0.seconds, settings.retryInterval, new Runnable {
    override def run() = notificationChannel ! SubscribeReplicator(source.logId, target.logId, self, replicationFilter)
  })

  var lastSourceLogSequenceNrStored = 0L
  var readSchedule: Option[Cancellable] = None

  val initializing: Receive = {
    case GetLastSourceLogReadPositionSuccess(_, lastSourceLogSequenceNrStored) =>
      this.lastSourceLogSequenceNrStored = lastSourceLogSequenceNrStored
      context.become(idle)
      self ! ReplicationDue
    case GetLastSourceLogReadPositionFailure(cause) =>
      log.error(cause, s"replication progress read failed")
      scheduleFetch()
  }

  val idle: Receive = {
    case ReplicationDue =>
      readSchedule.foreach(_.cancel()) // if it's a server-side notification that is concurrent to a scheduled read
      context.become(reading)
      read()
  }

  val reading: Receive = {
    case ReplicationReadSuccess(events, lastSourceLogSequenceNrRead, _) =>
      assert(lastSourceLogSequenceNrRead >= lastSourceLogSequenceNrStored,
        "illegal reply with lastSourceLogSequenceNrRead < lastSourceLogSequenceNrStored")
      failureDetector ! Tick
      context.become(writing)
      write(events, lastSourceLogSequenceNrRead)
    case ReplicationReadFailure(cause, _) =>
      log.error(s"replication read failed: $cause")
      context.become(idle)
      scheduleRead()
  }

  val writing: Receive = {
    case ReplicationWriteSuccess(num, lastSourceLogSequenceNrStored) if num == 0 =>
      this.lastSourceLogSequenceNrStored = lastSourceLogSequenceNrStored
      context.become(idle)
      scheduleRead()
    case ReplicationWriteSuccess(num, lastSourceLogSequenceNrStored) =>
      this.lastSourceLogSequenceNrStored = lastSourceLogSequenceNrStored
      context.become(reading)
      read()
    case ReplicationWriteFailure(cause) =>
      log.error(cause, s"replication write failed")
      context.become(initializing)
      fetch()
  }

  def receive = initializing

  private def scheduleFetch(): Unit = {
    scheduler.scheduleOnce(settings.retryInterval)(fetch())
  }

  private def scheduleRead(): Unit = {
    readSchedule = Some(scheduler.scheduleOnce(settings.retryInterval, self, ReplicationDue))
  }

  private def fetch(): Unit = {
    implicit val timeout = Timeout(settings.readTimeout)

    target.log ? GetLastSourceLogReadPosition(source.logId) recover {
      case t => GetLastSourceLogReadPositionFailure(t)
    } pipeTo self
  }

  private def read(): Unit = {
    implicit val timeout = Timeout(settings.readTimeout)

    source.log ? ReplicationRead(lastSourceLogSequenceNrStored + 1, settings.batchSizeMax, replicationFilter, target.logId) recover {
      case t => ReplicationReadFailure(t.getMessage, target.logId)
    } pipeTo self
  }

  private def write(events: Seq[DurableEvent], lastSourceLogSequenceNrRead: Long): Unit = {
    implicit val timeout = Timeout(settings.writeTimeout)

    target.log ? ReplicationWrite(events, source.logId, lastSourceLogSequenceNrRead) recover {
      case t => ReplicationWriteFailure(t)
    } pipeTo self
  }

  override def preStart(): Unit = {
    fetch()
  }
}

private object ReplicationServerFailureDetector {
  case object Tick
}

private class ReplicationServerFailureDetector(sourceEndpointId: String, logName: String, failureDetectionLimit: FiniteDuration) extends Actor {
  import ReplicationServerFailureDetector._
  import ReplicationEndpoint._

  val failureDetectionLimitMillis = failureDetectionLimit.toMillis
  var lastTick: Long = 0L

  context.setReceiveTimeout(failureDetectionLimit)

  def receive = {
    case Tick =>
      val currentTime = System.currentTimeMillis
      val lastInterval =  currentTime - lastTick
      if (lastInterval >= failureDetectionLimitMillis) {
        context.system.eventStream.publish(Available(sourceEndpointId, logName))
        lastTick = currentTime
      }
    case ReceiveTimeout =>
      context.system.eventStream.publish(Unavailable(sourceEndpointId, logName))
  }
}

private object NotificationChannel {
  val Name = "notifications"
}

/**
 * Notifies registered [[Replicator]]s about source log updates.
 */
private class NotificationChannel extends Actor {
  // targetLogId -> subscription
  var registry: Map[String, SubscribeReplicator] = Map.empty

  // targetLogIds for which a read operation is in progress
  var reading: Set[String] = Set.empty

  def receive = {
    case r @ SubscribeReplicator(_, targetLogId, _, _) =>
      registry += (targetLogId -> r)
    case Updated(sourceLogId, events) =>
      registry.foreach {
        case (targetLogId, reg) => if (sourceLogId == reg.sourceLogId && events.exists(reg.filter.apply)) {
          if (!reading.contains(targetLogId)) reg.replicator ! ReplicationDue
          else { /* skip sending a notification, read is in progress anyway */ }
        }
      }
    case r: ReplicationRead =>
      reading += r.targetLogId
    case r: ReplicationReadSuccess =>
      reading -= r.targetLogId
    case r: ReplicationReadFailure =>
      reading -= r.targetLogId
  }

  override def preStart(): Unit = {
    val stream = context.system.eventStream
    stream.subscribe(self, classOf[Updated])
    stream.subscribe(self, classOf[ReplicationRead])
    stream.subscribe(self, classOf[ReplicationReadSuccess])
    stream.subscribe(self, classOf[ReplicationReadFailure])
  }

  override def postStop(): Unit = {
    context.system.eventStream.unsubscribe(self)
  }
}
